{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9410f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>LC50 [-LOG(mol/L)]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.260</td>\n",
       "      <td>0.829</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.453</td>\n",
       "      <td>3.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.189</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.125</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.348</td>\n",
       "      <td>3.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.027</td>\n",
       "      <td>0.331</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.807</td>\n",
       "      <td>3.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.094</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.886</td>\n",
       "      <td>5.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
       "0  3.260      0.829   1.676    0.0      1  1.453               3.770\n",
       "1  2.189      0.580   0.863    0.0      0  1.348               3.115\n",
       "2  2.125      0.638   0.831    0.0      0  1.348               3.531\n",
       "3  3.027      0.331   1.472    1.0      0  1.807               3.510\n",
       "4  2.094      0.827   0.860    0.0      0  1.886               5.390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908 entries, 0 to 907\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   CIC0                906 non-null    float64\n",
      " 1   SM1_Dz(Z)           906 non-null    float64\n",
      " 2   GATS1i              906 non-null    float64\n",
      " 3   NdsCH               907 non-null    float64\n",
      " 4   NdssC               908 non-null    int64  \n",
      " 5   MLOGP               905 non-null    float64\n",
      " 6   LC50 [-LOG(mol/L)]  906 non-null    float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 49.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"qsar_fish_toxicity.csv\")\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2ff053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIC0                  2\n",
       "SM1_Dz(Z)             2\n",
       "GATS1i                2\n",
       "NdsCH                 1\n",
       "NdssC                 0\n",
       "MLOGP                 3\n",
       "LC50 [-LOG(mol/L)]    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259be50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04fafdc7",
   "metadata": {},
   "source": [
    "# Imputation of missing values\n",
    "# Mean/Median/Mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62fd49be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIC0                  0\n",
       "SM1_Dz(Z)             0\n",
       "GATS1i                0\n",
       "NdsCH                 0\n",
       "NdssC                 0\n",
       "MLOGP                 0\n",
       "LC50 [-LOG(mol/L)]    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values with appropriate methods\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# Verify that there are no missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3f22f",
   "metadata": {},
   "source": [
    "# KNN Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e37d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "CIC0                  0\n",
      "SM1_Dz(Z)             0\n",
      "GATS1i                0\n",
      "NdsCH                 0\n",
      "NdssC                 0\n",
      "MLOGP                 0\n",
      "LC50 [-LOG(mol/L)]    0\n",
      "dtype: int64\n",
      "\n",
      "Data after KNN Imputation:\n",
      "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
      "0  3.260      0.829   1.676    0.0    1.0  1.453               3.770\n",
      "1  2.189      0.580   0.863    0.0    0.0  1.348               3.115\n",
      "2  2.125      0.638   0.831    0.0    0.0  1.348               3.531\n",
      "3  3.027      0.331   1.472    1.0    0.0  1.807               3.510\n",
      "4  2.094      0.827   0.860    0.0    0.0  1.886               5.390\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Impute missing values using KNN\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "data_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(data_imputed.isnull().sum())\n",
    "\n",
    "# Display the first few rows of the imputed dataset\n",
    "print(\"\\nData after KNN Imputation:\")\n",
    "print(data_imputed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0768cd",
   "metadata": {},
   "source": [
    "# Linear Regression Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b027aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "CIC0                  0\n",
      "SM1_Dz(Z)             0\n",
      "GATS1i                0\n",
      "NdsCH                 0\n",
      "NdssC                 0\n",
      "MLOGP                 0\n",
      "LC50 [-LOG(mol/L)]    0\n",
      "dtype: int64\n",
      "\n",
      "Data after Regression Imputation:\n",
      "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
      "0  3.260      0.829   1.676    0.0      1  1.453               3.770\n",
      "1  2.189      0.580   0.863    0.0      0  1.348               3.115\n",
      "2  2.125      0.638   0.831    0.0      0  1.348               3.531\n",
      "3  3.027      0.331   1.472    1.0      0  1.807               3.510\n",
      "4  2.094      0.827   0.860    0.0      0  1.886               5.390\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to perform regression imputation\n",
    "def regression_imputation(df, target):\n",
    "    # Separate data into features and target\n",
    "    features = df.drop(columns=[target])\n",
    "    target_data = df[target]\n",
    "    \n",
    "    # Create mask for missing values in target\n",
    "    missing_mask = target_data.isnull()\n",
    "    \n",
    "    # Split data into training and prediction sets\n",
    "    X_train = features[~missing_mask]\n",
    "    y_train = target_data[~missing_mask]\n",
    "    X_pred = features[missing_mask]\n",
    "    \n",
    "    # Train the regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict missing values\n",
    "    predicted_values = model.predict(X_pred)\n",
    "    \n",
    "    # Fill in the missing values\n",
    "    df.loc[missing_mask, target] = predicted_values\n",
    "    return data\n",
    "\n",
    "# Perform regression imputation for each column with missing values\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        data = regression_imputation(df, column)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display the first few rows of the imputed dataset\n",
    "print(\"\\nData after Regression Imputation:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432753a4",
   "metadata": {},
   "source": [
    "# Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a35501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "CIC0                  0\n",
      "SM1_Dz(Z)             0\n",
      "GATS1i                0\n",
      "NdsCH                 0\n",
      "NdssC                 0\n",
      "MLOGP                 0\n",
      "LC50 [-LOG(mol/L)]    0\n",
      "dtype: int64\n",
      "\n",
      "Data after Linear Interpolation:\n",
      "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
      "0  3.260      0.829   1.676    0.0      1  1.453               3.770\n",
      "1  2.189      0.580   0.863    0.0      0  1.348               3.115\n",
      "2  2.125      0.638   0.831    0.0      0  1.348               3.531\n",
      "3  3.027      0.331   1.472    1.0      0  1.807               3.510\n",
      "4  2.094      0.827   0.860    0.0      0  1.886               5.390\n"
     ]
    }
   ],
   "source": [
    "# Perform linear interpolation\n",
    "data_interpolated = df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(data_interpolated.isnull().sum())\n",
    "\n",
    "# Display the first few rows of the imputed dataset\n",
    "print(\"\\nData after Linear Interpolation:\")\n",
    "print(data_interpolated.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad404b0",
   "metadata": {},
   "source": [
    "# Stochastic Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603a00a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "CIC0                  0\n",
      "SM1_Dz(Z)             0\n",
      "GATS1i                0\n",
      "NdsCH                 0\n",
      "NdssC                 0\n",
      "MLOGP                 0\n",
      "LC50 [-LOG(mol/L)]    0\n",
      "dtype: int64\n",
      "\n",
      "Data after Stochastic Imputation:\n",
      "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
      "0  3.260      0.829   1.676    0.0      1  1.453               3.770\n",
      "1  2.189      0.580   0.863    0.0      0  1.348               3.115\n",
      "2  2.125      0.638   0.831    0.0      0  1.348               3.531\n",
      "3  3.027      0.331   1.472    1.0      0  1.807               3.510\n",
      "4  2.094      0.827   0.860    0.0      0  1.886               5.390\n"
     ]
    }
   ],
   "source": [
    "# Function to perform stochastic imputation\n",
    "\n",
    "def stochastic_imputation(df, target):\n",
    "    \n",
    "    # Separate data into features and target\n",
    "    features = df.drop(columns=[target])\n",
    "    target_data = df[target]\n",
    "    \n",
    "    # Create mask for missing values in target\n",
    "    missing_mask = target_data.isnull()\n",
    "    \n",
    "    # Split data into training and prediction sets\n",
    "    X_train = features[~missing_mask]\n",
    "    y_train = target_data[~missing_mask]\n",
    "    X_pred = features[missing_mask]\n",
    "    \n",
    "    # Train the regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict missing values\n",
    "    predicted_values = model.predict(X_pred)\n",
    "    \n",
    "    # Calculate the standard deviation of the residuals\n",
    "    residuals = y_train - model.predict(X_train)\n",
    "    std_dev = np.std(residuals)\n",
    "    \n",
    "    # Add normally distributed noise to the predicted values\n",
    "    noise = np.random.normal(0, std_dev, size=predicted_values.shape)\n",
    "    stochastic_predictions = predicted_values + noise\n",
    "    \n",
    "    # Fill in the missing values\n",
    "    df.loc[missing_mask, target] = stochastic_predictions\n",
    "    return df\n",
    "\n",
    "# Perform stochastic imputation for each column with missing values\n",
    "for column in df.columns:\n",
    "    if df[column].isnull().sum() > 0:\n",
    "        df = stochastic_imputation(df, column)\n",
    "\n",
    "# Check for missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display the first few rows of the imputed dataset\n",
    "print(\"\\nData after Stochastic Imputation:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c6e46",
   "metadata": {},
   "source": [
    "#  Boxplot to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43321996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df)\n",
    "plt.title('Boxplot for Outlier Detection')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04cdccf",
   "metadata": {},
   "source": [
    "INSIGHTS:\n",
    "\n",
    "Here we can clearly see that ouliers are  present in each of the variable set. So we need to perform the ouliers removal\n",
    "\n",
    "We can also use scatterplot, histogram to visualise the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2c608",
   "metadata": {},
   "source": [
    "# OUTLIERS DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f9c63e",
   "metadata": {},
   "source": [
    "Z- SCORE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b02c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CIC0': [5.926],\n",
       " 'SM1_Dz(Z)': [2.044, 2.171, 2.071],\n",
       " 'GATS1i': [2.698, 2.606, 4.98, 2.609, 2.672, 2.92, 2.539, 2.591],\n",
       " 'NdsCH': [3.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0],\n",
       " 'NdssC': [4, 4, 4, 4, 4, 20, 4, 4, -3, 5, 4, 6, 6],\n",
       " 'MLOGP': [10.0, -5.78, -2.884],\n",
       " 'LC50 [-LOG(mol/L)]': [8.471, 9.612, 8.571, 8.604, 9.354, 8.916, 8.433]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to detect outliers using Z-Score\n",
    "def detect_outliers_z_score(df, threshold=3):\n",
    "    mean = np.mean(df)\n",
    "    std = np.std(df)\n",
    "    z_scores = [(x - mean) / std for x in df]\n",
    "    outliers = [x for x, z in zip(df, z_scores) if np.abs(z) > threshold]\n",
    "    return outliers\n",
    "\n",
    "# Applying Z-Score method to each numerical column\n",
    "z_score_outliers = {}\n",
    "for column in df.select_dtypes(include=[np.number]).columns:\n",
    "    outliers = detect_outliers_z_score(df[column].dropna())\n",
    "    z_score_outliers[column] = outliers\n",
    "\n",
    "z_score_outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ab83a",
   "metadata": {},
   "source": [
    "IQR METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbfd4b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CIC0': [0.667, 5.926, 0.667, 5.158],\n",
       " 'SM1_Dz(Z)': [2.044, 2.171, 2.071],\n",
       " 'GATS1i': [2.698, 2.606, 4.98, 2.609, 2.672, 2.92, 2.539, 2.591],\n",
       " 'NdsCH': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  0.22932745314222713,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0],\n",
       " 'NdssC': [3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  20,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  4,\n",
       "  -3,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  3,\n",
       "  3,\n",
       "  6,\n",
       "  3],\n",
       " 'MLOGP': [6.203, -1.96, -2.03, 6.515, 6.166, 10.0, -5.78, -2.884, -2.089],\n",
       " 'LC50 [-LOG(mol/L)]': [0.45,\n",
       "  7.899,\n",
       "  0.053,\n",
       "  0.15,\n",
       "  0.33,\n",
       "  8.471,\n",
       "  9.612,\n",
       "  7.809,\n",
       "  7.691,\n",
       "  8.571,\n",
       "  8.207,\n",
       "  8.132,\n",
       "  8.169,\n",
       "  7.64,\n",
       "  0.242,\n",
       "  0.361,\n",
       "  8.604,\n",
       "  9.354,\n",
       "  7.607,\n",
       "  7.591,\n",
       "  7.849,\n",
       "  8.916,\n",
       "  8.433,\n",
       "  8.201]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to detect outliers using IQR\n",
    "def detect_outliers_iqr(df):\n",
    "    Q1 = np.percentile(df, 25)\n",
    "    Q3 = np.percentile(df, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = [x for x in df if x < lower_bound or x > upper_bound]\n",
    "    return outliers\n",
    "\n",
    "# Applying IQR method to each numerical column\n",
    "iqr_outliers = {}\n",
    "for column in df.select_dtypes(include=[np.number]).columns:\n",
    "    outliers = detect_outliers_iqr(df[column].dropna())\n",
    "    iqr_outliers[column] = outliers\n",
    "\n",
    "iqr_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8c52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after removing outliers:\n",
      "    CIC0  SM1_Dz(Z)  GATS1i  NdsCH  NdssC  MLOGP  LC50 [-LOG(mol/L)]\n",
      "0  3.260      0.829   1.676    0.0    1.0  1.453               3.770\n",
      "1  2.189      0.580   0.863    0.0    0.0  1.348               3.115\n",
      "2  2.125      0.638   0.831    0.0    0.0  1.348               3.531\n",
      "3  3.027      0.331   1.472    1.0    0.0  1.807               3.510\n",
      "4  2.094      0.827   0.860    0.0    0.0  1.886               5.390\n",
      "Total number of rows after outlier removal: 833\n"
     ]
    }
   ],
   "source": [
    "df_noMV = imputer.fit_transform(df)\n",
    "\n",
    "df_noMV = pd.DataFrame(df_noMV, columns = df.columns)\n",
    "\n",
    "# Step 1: Identify numerical columns excluding 'NdsCH'\n",
    "numerical_cols = df_noMV.select_dtypes(include=np.number).columns\n",
    "numerical_cols = numerical_cols[numerical_cols != 'NdsCH']  # Exclude 'NdsCH'\n",
    "\n",
    "# Step 2: Define a function to find outliers using IQR method\n",
    "def find_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Step 3: Remove outliers from all numerical columns except 'NdsCH'\n",
    "for column in numerical_cols:\n",
    "    lower_bound, upper_bound = find_outliers_iqr(df_noMV, column)\n",
    "    df_noMV = df_noMV[(df_noMV[column] >= lower_bound) & (df_noMV[column] <= upper_bound)]\n",
    "\n",
    "# Display the new dataframe without outliers\n",
    "print(\"DataFrame after removing outliers:\")\n",
    "print(df_noMV.head())\n",
    "\n",
    "# Step 4: Verify the total number of rows after outlier removal\n",
    "print(f\"Total number of rows after outlier removal: {len(df_noMV)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24653380",
   "metadata": {},
   "source": [
    "# DESCRIPTIVE STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "480a04a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics:\n",
      "             CIC0   SM1_Dz(Z)      GATS1i       NdsCH       NdssC       MLOGP  \\\n",
      "count  833.000000  833.000000  833.000000  833.000000  833.000000  833.000000   \n",
      "mean     2.868766    0.604885    1.276216    0.216362    0.379352    2.120826   \n",
      "std      0.727881    0.414123    0.374748    0.581214    0.641255    1.317599   \n",
      "min      0.965000    0.000000    0.396000    0.000000    0.000000   -1.306000   \n",
      "25%      2.309000    0.223000    0.945000    0.000000    0.000000    1.246000   \n",
      "50%      2.893000    0.560000    1.227000    0.000000    0.000000    2.127000   \n",
      "75%      3.380000    0.880000    1.556000    0.000000    1.000000    3.026000   \n",
      "max      4.880000    1.825000    2.456000    4.000000    2.000000    5.741000   \n",
      "\n",
      "       LC50 [-LOG(mol/L)]  \n",
      "count          833.000000  \n",
      "mean             4.001377  \n",
      "std              1.275078  \n",
      "min              0.778000  \n",
      "25%              3.168000  \n",
      "50%              3.971000  \n",
      "75%              4.811000  \n",
      "max              7.382000  \n"
     ]
    }
   ],
   "source": [
    "# Display descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(df_noMV.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a063071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFvCAYAAAB0NxGZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9GUlEQVR4nO3dd3hc5Zn38e+t3ptVLKvZcsMFjMHYEMB000tCEiAkQBrJbkISSHlJNn2zCynr7CabZEMqIQRCIIAJzWDANjFgjI1x77Ys2+qW1evc7x9zBLIs2ZKtmWfK/bmuuaQ5c2bmJ2l0z5nnPEVUFWOMMcEX4zqAMcZEKyvAxhjjiBVgY4xxxAqwMcY4YgXYGGMcsQJsjDGOWAE2xhhHrACHOBH5PxH51ig9VqmItIhIrHf9FRH51Gg8tvd4z4rIraP1eCN43h+ISJ2IVAX7uYdLRM4XEZ/3+78sBPL8U0RmB+Bxvysifz6O+31BRO4dsO0lEekQkVdHL2FosQLskIjsFpF2EWkWkUYRWSEinxWRd/8uqvpZVf33YT7WxUfbR1UrVDVNVXtHIfsR/2iqermq3n+ijz3CHCXAl4Hpqjp2kNvPF5HKo9x/rog84/3+G0RkpYh83LttvIioVzT7Lt/qd18RkR+KSL13+ZGIyFHi7vd+/88dJY+KyKQhbrvKy9fqPd+DIlI8YJ9CEfmNiOz38u4UkT+KyEn99rkaaFbVNUfJOmpE5CMi8pd+v8+4QXa7D/ioiOT3bVDVC4HPBiOjK1aA3btaVdOBMuBe4P8BvxvtJxniRR8JyoB6Va0Z6R1F5CzgJWApMAkYA/wLcPmAXbO8wpk24M3wduA6YBZwCnAV8JkR/wTDy/pB4C/A/wC5wAygE3hVRLK9fcYAK4AU4FwgHTjN+/ku6fdwnwUeCETOIVwBPHO0HVS1A3gWuCUoiUKFqtrF0QXYDVw8YNtcwAfM9K7/EfiB930u8A+gEWgAluN/E33Au0870AJ8DRgPKPBJoAJY1m9bnPd4rwD3ACuBQ8CTQI532/lA5WB5gcuALqDbe761/R7vU973McA3gT1ADfAnINO7rS/HrV62OuDfjvJ7yvTuX+s93je9x7/Y+5l9Xo4/DnLfI36Ofre9CvziKM972O9rkNtXALf3u/5J4PUh9h0yx4D9FJg0YJt4P/fXBmyPAdYD3/eu/wBYC8Qc5fETvN9Zcb9t3wX+BvwZaAbWAVOAr3t/u73Agn77jwMWea/B7cCnBzzWnwdkrMb/2j3W7/Nm4OUB224DXnX9vxqoix0BhxhVXQlU4j+CGejL3m15QAHwDf9d9GP4C9nV6j9K+1G/+5wHTAMuHeIpbwE+gf+fqgf42TAyPgf8J/BX7/lmDbLbbd7lAqAcSAP+d8A+5wBTgYuAb4vItCGe8uf4i3C59/PcAnxcVV/Ef7Ta99H+tmNl7yMiKcBZwKPD2H2PiFSKyB9EJLff9hn4C16ftd620TYVKMVfJN+lqj7gMd47ur0YeNzbPpTJgE9VBzbLXI3/jTwbWAM8j794FgHfB37db9+H8L8OxwEfBP5TRC4a4vnmAjtVte5oP6BnE/5PE1HDCnBo2g/kDLK9GygEylS1W1WXq3eYcBTfVdVWVW0f4vYHVHW9qrYC3wI+3HeS7gTdDCxU1Z2q2oL/aOrGAU0h31PVdlVdi794HfHP52W5Afi6qjar6m7gv4CPnWC+bPyv/wNH2acOOAN/M8fp+D/SP9jv9jT8nxz6HALSjtEOfDz6iv5gWQ/0uz0XePdEpIhc47VtN4vIYm9zFv6j3IGWq+rzqtqDv9DnAfeqajfwMDBeRLK8NvdzgP+nqh2q+jbwW4b+e1zJMZof+mnG/0YbNawAh6Yi/B/vBvox/o98i72TK3cP47H2juD2PUA87/1Dn4hx3uP1f+w4/Efuffr3WmjDX9AGysX/sXngYxWdYL6D+JsuCofaQVVbVHWVqvaoajXweWCBiGR4u7QAGf3ukgG0DONNEQAR2dDv5N5gn3j69B09Dpa1sN/t9f33UdVFqpoF3In/dwj+nzt9kMep7vd9O1Cn752s7XvzTsP/d21Q1f5F/Gh/j2O2//aTzuFvaBHPCnCIEZEz8L+Yj+h64x0BfllVy/F/ZLyr30e/of7pj1UMSvp9X4r/KLsOaMV/MqcvVyz+o6LhPu5+/EeO/R+7h8P/0Yejzss08LH2jfBxDqOqbcBrwPUjuZv3te8IdwOHH7XP8rYNN8MMfe/k3vKj7LoF/0f+D/Xf6PWWuR5Y4m1aAlzXvxfNILb57yrH+wa2H8gRkf5FfNC/h4iMxf+GsHqYjz2Nw5t0Ip4V4BAhIhkichX+j3t/VtV1g+xzlYhM8j7iNgG93gX8ha38OJ76oyIy3WsT/T7wqHfksxVIEpErRSQe/4mvxH73q8b/sXSo19BDwJ0iMkFE0nivzbhnJOG8LI8A/yEi6SJSBtyF/4TRsIlI0oCL4D9ZeZuIfNXrQYCIzBKRh73v54nIVBGJ8W7/GfCKqvYdpf0J/5tgkYiMw99G/8eR5BpCQv+s+P9PvwJ80+vSlewVt9/iP+r+qXe/hfibVh4QkYleN7l04NS+B/aaFF7E35Y+Yqq6F//Jx3u8fKfgP/n44CC7XwE8N8gngsQBf4u+19B5+HtCRA0rwO49JSLN+JsC/g3/P9HHh9h3Mv5/nhb8R2+/VNVXvNvuwf8P2igiXxnB8z+Av2hUAUnAFwC8IvOv+P/J9+E/Iu5/4qbvhFC9iAx2hPN777GXAbuADuCOEeTq7w7v+Xfi/2TwF+/xh6sI/8fo/peJqroCuNC77BSRBvz9Ufs+MpcDz+Fvm1yPv9vXTf0e99fAU/h7DawHnubwk1XHa8OArB9X1b/ib2e9E/+ngo1AMnC2qtYDeCe6zsT/u37Vy/02/o/2/zIg94m0od+Ev0fDfuBx4Duq+sIg+w3V/NAy4Oe70HujuQIIaj9y12SYzVXGmBMgIvPx9yzoBG5Q1ecd53kVuEMDNBjDO9lahf+N7pjtuiJyB1Ciql/rt+0F/G8oK1V1qF4WYc0KsDFm1Hkj2q5X1V+5zhLKrAAbY4wj1gZsjDGOBKwAi8jvRaRGRNb325YjIi+IyDbva3a/274uIttFZIuIDDVqyxhjIkYgj4D/iH/OgP7uBpao6mT8fRbvBhCR6cCN+IdxXgb8cjijsS677DLF3zfTLnaxi11C+TKogBVgVV3GkaO5ruW9bib3459Jqm/7w6raqaq78I/2mnus56irG87wcmOMCU3BbgMuUNUDAN7Xvrk/izh8SGwlQwxtFJHbRWSViKyqra0NaFhjjAmkUDkJN9jkJYMetqvqfao6R1Xn5OXlDbaLMcaEhWAX4GoRKQT/zP345xoF/xFv/zkJivGPsjHGmIgV7AK8CP8k3Hhfn+y3/UYRSRSRCfiH3K4McjZjjAmqgC1TIyIP4V8FIFf8a3J9B/+SO4+ISN8qDR8CUNUNIvII/vHtPcDndBTWLTPGmFAW1iPh5syZo6tWrXIdwxhjjmXQSfpD5SScMcZEHSvAxhjjiBVgY4xxxAqwMcY4YgXYGGMcsQJsjDGOWAE2YauktAwRGfGlpLTMdXRjgAAOxDAm0Cr3VrBw8ZYR3++uBVMDkMaYkbMjYGOMccQKsDHGOGIF2BhjHLECbIwxjlgBNsYYR6wAG2OMI1aAjTHGESvAxhjjiBVgY4xxxAqwMcY4YgXYGGMcsQJsjDGOWAE2xhhHrAAbY4wjVoCNMcYRK8DGGOOITchuIpKqUtfSxcG2Lnp9SlJ8LPnpiaQm2kvehA57NZqI0utT3qls5O29jTR19Bxxe356IumnXUVbVw8pCSN/+ZeUllG5t2LE9ysuKWVvxZ4R389ENivAJmIcbOvi6XcOUN/aRVFWMnMn5JCfnkR8rNDW1cuBQx1srW4m55LPcs4PX+YrC6ZywxklxMbIsJ/DlkEyo8nagE1E2NfYzsNv7qWtq5erTynk+tOKmDEuk7z0RLJSEhiXlczpZdncNLeUqj9/hUn5aXzj8XVc+4tXWV1x0HV8E6WsAJuwV93UwaK395OaEMuNZ5RQnpeGyNBHtZ37NvPX28/kZzfNpq65iw/+agULF2+hu9cXxNTGWAE2Ya61s4en1u4nKT6G988uIiM5flj3ExGumTWOF798Hh84rZifvbSdD/3fa+yuaw1wYmPeYwXYhC+J4dn1VXT2+LjqlHGkJw2v+PaXlhjHTz40i1985DR21rZwxc+W87dVewMQ1pgjWQE2YSv99KvZ19jOBVPzyUtPPKHHuvKUQp770nxOKc7kq4++w9ceXUtHd+8oJTVmcFaATVjaU99K1vyPMX5MCtMK00flMcdlJfPgp87kCxdO4pFVlXzglyuoqG8blcc2ZjBWgE1Y+sHTm8Dn48KT8o96wm2kYmOEuxZM5fe3zaHyYBtX/Xw5L26sHrXHN6Y/K8Am7KzYUccLG6s59PrfjqvddzguPKmAp79wLiU5KXzqT6v48fOb6fVpQJ7LRC8rwCasqCr3PLOZoqxkmlc9GdDnKslJ4bF/eR83nlHCL17ewe1/WoXEJwX0OU10sQJswsqSTTWs23eIL108Ge3pCvjzJcXHcu/1p/Dv183k5S01jL35hzR3dAf8eU10sAJswoaq8t9LtlI2JoX3zy4K6nN/7Mwyfn/bGcRlFfLIqkoaWgNf/E3kswJswsbSrbWs39fE5y+YRFxs8F+650/Np+rBr+FT5bHVldS3dAY9g4ksVoBN2PjN8p0UZCRy7anBPfrtr7t2N9efVowAj63eR50VYXMCrACbsLB+3yH+ub2ej589gYQ4ty/bnNQErj+9mNgY4fE1+2iyNmFznKwAm7Bw/4rdpCTEctPcUtdRAMhOSeD9s4vo8SlPrd1PV49N5GNGzgqwCXlNHd089c5+rj11HJnDnGwnGHJSE7hi5ljqW7t4bkMVPrV+wmZkrACbkPfkmn10dPtC5ui3v7IxqZw/JY9dda28tqPedRwTZqwAm5Cmqjz4RgUzxmVwclGm6ziDOqU4ixnjMli15yAVDTZ3hBk+K8AmpK2tPMTmqmY+Mq90VOd8GG3nTckjJyWBxRuq6LRZ1MwwWQE2zpWUliEig14uuv3b+Lra+dj8aUfcdtwkZsjnO9ZlKPGxMSyYUUBbdy/LttUdfzYTVWxRTuPcUAtddvb08tvlu5g6Np07//H2Ebcf90KX6juuhTWP9ZwFGUmcXprNqj0HOWlsOiU5KceXz0QNOwI2IWt7TQs9PmXmuNBs+x3MvAk5ZCbH88rWWps9zRyTFWATsrZUN5OZHE9BxomtdhFMcbExzJ+cS0NrF+9UNrqOY0KcFWATklo7e6hsaGfq2PSQPvk2mAm5qZTmpPDm7oM2QMMclZMCLCJ3isgGEVkvIg+JSJKI5IjICyKyzfua7SKbCQ1bq5tRYGrB6Cw3FEwiwlnlY2jv7uXtvY2u45gQFvQCLCJFwBeAOao6E4gFbgTuBpao6mRgiXfdRKkt1c3kpyeSk5rgOspxGZuZRHluKm9VHLTFPc2QXDVBxAHJIhIHpAD7gWuB+73b7weucxPNuHawrYvqps6wPPrt78zyMXT1+FhT0eg6iglRQS/AqroP+AlQARwADqnqYqBAVQ94+xwA8oOdzYSGrVXNAEwuSHOc5MTkpScyOT+NNXsPEpOc4TqOCUEumiCy8R/tTgDGAaki8tER3P92EVklIqtqa2sDFdM4oqpsqW6mOCs5YAtuBtOZ5WPo7lXST7vKdRQTglw0QVwM7FLVWlXtBv4OvA+oFpFCAO9rzWB3VtX7VHWOqs7Jy8sLWmgTHA2tXRxs6w77o98+OakJTMhNJX325dYWbI7gogBXAGeKSIr4+xddBGwCFgG3evvcCgR2yVsTkrbXtgAwMS8yCjDAqSVZxKZm89Ta/a6jmBDjog34DeBRYDWwzstwH3AvcImIbAMu8a6bKLO9poVxmUmkJkbOKPmS7GS6anfz+3/uRm3OYNOPk1e5qn4H+M6AzZ34j4ZNlGps66KupYtzJ+e6jjKqRITmVU+yKW88r+9s4KyJY1xHMiHCRsKZkLGjthWASRHU/NCndeNSclIT+P0/d7mOYkKIFWATMnbUtpCfnkhGCC07NFq0p4ub55Xy4qZqKg/apO3GzwqwCQktnT0cONTBxPzIO/rtc8MZJQA8+lal4yQmVFgBNiFhh9f7IRKbH/oUZ6dwzqRc/raqEp9NVWmwAmxCxI7aFrJT4sN27ofh+vCcEvY1tvPPHbZqhrECbEKAJCSz72A75RF89NvnkukFZCbH89c397qOYkKAFWDjXPKE0/Cpfx7dSJcUH8v7ZxexeEM1jW1druMYx6wAG+eSJ80jKT6Gwswk11GC4sNzSujq9fHEmn2uoxjHrAAbp3p9SnL56Ywfk0pMmK18cbymj8tgZlEGf7PeEFHPCrBxanXFQWJTMimPguaH/t4/u5gN+5vYXtPiOopxyAqwcerFTdVobzelY6JrCferTilEBBbZBD1RzQqwcWrJpho69q4nMS7WdZSgKshI4qzyMTy1dr9N0BPFrAAbZ/bUt7K9poX27StdR3Himlnj2FXXyrp9h1xHMY5YATbOLNnkn3M/KgqwxCAih11unj8d7e3m/Fu+csRtfZeS0jLXyU0ARc6kqybsLNtWS3luKnsOVbuOEnjqY+HiLUdsfmrtfqrP/SD/dvdXB+0FcteCqcFIZxyxI2DjRGdPL6/vrI+4uX9HaurYdFo7e9nf2O46inHACrBxYtXug3R0+5g/JbrX9ZuQm0p8rLC12rqjRSMrwMaJZVtriY8VziyP7tUh4mNjGD8mlR21LfisN0TUsQJsnFi6tZY5ZTkRtfbb8ZqUn0ZbVy8HGjtcRzFBZgXYBF1NUwebq5o5d0p0t//2GT8mldgYeXdFaBM9rACboFu+zT8X7vzJ0d3+2ychLoaynBS217TYoIwoYwXYBN2ybbXkpiUwvTDDdZSQMTE/jZbOHqqbOl1HMUFkBdgElc+nLN9Wx7mT84iJiY7Zz4ajPDeVGMGaIaKMFWATVBv2N9HQ2hX1/X8HSoqPpTjbmiGijRVgE1TLttUCcK61/x5hUn4ah9q7qWuxlTKihRVgE1TLttYyvTCDvPRE11FCzsS8VARrhogmVoBN0LR09vDWnoNRP/ptKCkJcYzLSmaHTdIeNawAm6B5bUc9PT5lvrX/DmlSfhr1rV0cbLVmiGhgBdiMmpLSsiGnVRQRbvjid/F1dXD2SYWHbTfvmZSXBsA2a4aICjYO1Iyayr0Vg0652OePK3aTnRLPnc9uOGy7Tbn4nrSkOMZmJLGztoW543NcxzEBZkfAJigOtXdzqL2bsjHRtfjm8ZiQl0p1UyctnT2uo5gAswJsgmJPfSsAZTnRtfjm8ZjorRC9q7bVcRITaFaATVBUNLSRnhRHVkq86yghLyc1gczkeHbUWTtwpLMCbAKu16fsbWinLCfFTroNg4hQnptKZUM7kpDsOo4JICvAJuCqDnXQ1euz9t8RKM9LpVeV5PGzXUcxAWQF2ATcnoZWRKAk247mhmtcZjJJcTEkTz7TdRQTQFaATcBVNLQxNiOJxPhY11HCRkyMMCE3leSJc+jp9bmOYwLECrAJqPauXqqbOq33w3GYkJdKbHIGb+4+6DqKCRArwCagKhraAKz99ziU5aSiPV28uKnadRQTIFaATUDtaWglMS6G/Ayb/WykEuJiaN+zlhc2VtscwRHKCrAJGFWloqGN0pwUYqz72XFp3/Y6FQ1tbK22PsGRyAqwCZj61i5aO3spHWPtv8erfcebALywscpxEhMIVoBNwFTUe+2/dgLuuPW2NDCrJIsXNtW4jmICwAqwCZg9DW3kpCSQnmTDj0/EgukFrN3bSHVTh+soZpRZATYB0d3rY19juzU/jIKLpxUAWG+ICGQF2ATE/sZ2en1KmRXgEzalII3SnBRe2GgFONJYATYBsae+jdgYoSjLhh+fKBHhkukFrNheT6vNERxRrACbgNjT0Ma4rCTiY+0lNhoumV5AV6+PZVtrXUcxo8j+O8yoa+7opqG1i7IcG/02WuaUZZOVEm/NEBHGCrAZde8NP7b239ESFxvDhVPzeWlLjU3OE0GsAJtRt6e+jdSEWMakJriOElEumV5AY1u3Tc4TQawAm1Hl6xt+PMZWvxht86fkkRAbY93RIoiTAiwiWSLyqIhsFpFNInKWiOSIyAsiss37mu0imzkxNU2ddPb4rP03AFIT43jfpDE2OU8EcXUE/D/Ac6p6EjAL2ATcDSxR1cnAEu+6CTN7Gvwr+Zba8OOAuGR6gU3OE0GCXoBFJAOYD/wOQFW7VLURuBa439vtfuC6YGczJ25PfRv56YkkJ9jqF4Fgo+Iii4sj4HKgFviDiKwRkd+KSCpQoKoHALyv+Q6ymRMgCSlUNXVY74cAKshIYlZJFoutO1pEcFGA44DTgF+p6myglRE0N4jI7SKySkRW1dZap/RQkjR+FqpY++9okhhE5LDLKw/+jLV7G4lLH3PEbX2XktIy18nNMMQ5eM5KoFJV3/CuP4q/AFeLSKGqHhCRQmDQ+fdU9T7gPoA5c+bYmYgQkjz+NBJiYxibmeQ6SuRQHwsXbzlsU11LJw++UcEtP3uOk4szB73bXQumBiOdOUFBPwJW1Spgr4j0vUIuAjYCi4BbvW23Ak8GO5s5fqpK8oTZFGcnExtj3c8CaUxqApnJ8eyosxNx4c7FETDAHcCDIpIA7AQ+jv/N4BER+SRQAXzIUTZzHHbVtRKXNdbaf4NARCjPTeWdykN09fhIiLPu/OHKSQFW1beBOYPcdFGQo5hR0jdJjHU/C47yvFTW7G1kT0Mrk/PTXccxx8neOs2oWL6tju6D+8lKseHHwTAuM5mkuBh21ra6jmJOgBVgc8K6eny8trOejl2rXUeJGjExwvjcVHbXteLz2bnocGUF2JywVXsaaOvqpd0KcFCV56XS0eNj/6F211HMcbICbE7Ysq11xMUIHRXrXEeJKmU5qcTGiDVDhDErwOaELdtay2ll2WiXHYkFU0JcDCXZyeysa7XJecKUFWBzQmqbO9l4oInzpuS5jhKVynPTONTeTX1rl+so5jhYATYn5NXt/u5n507OdZwkOk3I8w/7tmaI8DSsAiwij4nIlSJiBdscZumWWsakJjBz3OBDYk1gpSXGUZCRyE4bFReWhltQfwV8BNgmIveKyEkBzGTChM+nLNtWx/wpecTY8GNnyvPSqG7qpMWWrA87wyrAqvqiqt6Mfxaz3cALIrJCRD4uIvGBDGhC1zv7DtHQ2sX5U63916WJuf5miF3WDBF2ht2kICJjgNuATwFr8K9qcRrwQkCSmZC3dEstInDuZCvALuXY5Dxha1hzQYjI34GTgAeAq/smTgf+KiKrAhXOhLZXttZwSnEWObb6sVM2OU/4Gu5f6reqOl1V7+krviKSCKCqg02qYyLcwdYu1u5ttO5nIaI8L5VeVfbUWzNEOBluAf7BINteG80gJrws316HT7H23xDx7uQ8dVaAw8lRmyBEZCxQBCSLyGyg71R3BmDzDkaxpVtqyUqJZ1ZxlusoBv/kPBNyU9llk/OElWO1AV+K/8RbMbCw3/Zm4BsBymRCnM+nLN1ay7mT82z1ixAyIS+VTVXNNjlPGDlqAVbV+4H7ReR6VX0sSJlMiNt4oIm6lk7Ot/bfkNI3Oc8O644WNo7VBPFRVf0zMF5E7hp4u6ouHORuJsIt9Va/mG8FOKS8OzlPrXVHCxfHaoLoW188LdBBTPhYuqWWmUUZ5KUnuo5iBijPS2N3fQ3xubYsfTg4VhPEr72v3wtOHBPqDrV381bFQf7lvImuo5hBTPBGxSVPnuc4iRmO4U7G8yMRyRCReBFZIiJ1IvLRQIczoWfF9jp6fcp51v0sJPVNzpMy6UzXUcwwDLcf8AJVbQKuAiqBKcBXA5bKhKwlm2vISIpjdkmW6yhmCOV5aSSOm0J1U4frKOYYhluA+ybcuQJ4SFUbApTHhLBen/Ly5houOCmfuFgb7hqq+ibneWFjteMk5liG+1/0lIhsBuYAS0QkD7C31yjz9t6D1Ld2cdG0AtdRzFHkpCbQfXA/L26yAhzqhjsd5d3AWcAcVe0GWoFrAxnMhJ4XN9UQFyM2/0OIExHat69kxfZ6myM4xI3kc+Q04AYRuQX4ILAgMJFMqFqyqZq5E3LITLYpoENd27bX6er1sczrs21C03B7QTwA/AQ4BzjDu9gsaFGkor6NrdUt1vwQJjorN5KVEm/twCFuWPMB4y+209XWvo5afe2JF0/Ld5zEDIv6uPCkfJZsqqG710e8nTQNScP9q6wHxgYyiAltSzZXMzk/jbIxqcfe2YSEBdMLONTezardB11HMUMYbgHOBTaKyPMisqjvEshgJnQ0dXTzxs4Ga34IM+dOziMhLobFG6tcRzFDGG4TxHcDGcKEtqVbaunxqTU/hJnUxDjOmZTL4g3VfPuq6YjY1KGhZrjd0JbiXw053vv+TWB1AHOZELJkUzU5qQnMLs12HcWM0KUzCtjX2M6G/U2uo5hBDLcXxKeBR4Ffe5uKgCcClMmEkJ5eHy9vqeWCqfk2+XoYunhaATECz2+wZohQNNw24M8BZwNNAKq6DbDPo1Fg1Z6DHGrvtuaHMDUmLZEzxudYAQ5Rwy3Anara1XdFROIA65IWBV7cWE1CbAzn2ui3sHXZzLFsrW6xidpD0HAL8FIR+Qb+xTkvAf4GPBW4WCYUqCrPrq/i7EljSEsc7vlaE2oWzPD3IH1+gw3KCDXDLcB3A7XAOuAzwDPANwMVyoSG9fua2NfYzuUzC11HMSegKCuZk4syrRkiBA3rsEZVfSLyBPCEqtrg8ijx7PoDxMYIl0y3/r/h7rKZY/nx81uoOtTB2Mwk13GM56hHwOL3XRGpAzYDW0SkVkS+HZx4xhVV5bn1VZxZnkN2aoLrOOYEXTrD/yZqgzJCy7GaIL6Ev/fDGao6RlVzgHnA2SJyZ6DDGXe21bSws66Vy6z5ISJMyk9nYl6qNUOEmGMV4FuAm1R1V98GVd0JfNS7zUSYktIyRIS5H7gdVR+3XXwqIjKsiwltl84Yy+s7GzjY2nXsnU1QHKsNOF5V6wZuVNVaEbFJYSNQ5d4KFi7ewoNv7CEhNoYvPf7GsO9714KpAUxmTtSlM8byy1d2sGRzDR88vdh1HMOxj4CP9lZpb6MRqrGti7qWLiblp7mOYkbRKcWZFGYmWTNECDnWEfAsERlsELkAdio1Qm2t9nfYn2gFOKKICJfOGMtDKyto6+ohJcH6drt21CNgVY1V1YxBLumqak0QEWprdTOFmUlkJNmfONIsmFFAZ4+PpVusN2kosGnyzWHic8uob+1iakG66ygmAOaOzyE7JZ7nrBkiJFgBNodJnTYfASYXWPNDWJOYQXuqxMfFsvf1Z3j8jW1IbPyg+5SUlrlOHzWsEci8S1VJmTafkpwUax8Md+pj4eItg960q66VRWv3c8efVzIh98glpqw3S/DYEbB519rKQ8RnFzLFjn4jWmlOColxMWytbnYdJepZATbvWvT2frSnm0l5VoAjWWyMMDEvjZ21rfT0+lzHiWpWgA0AvT7l6XX7ad+5isT4WNdxTIBNKUijq9fHnoY211GimhVgA8CKHXVUN3XSummp6ygmCIqzU0iKt2YI15wVYBGJFZE1IvIP73qOiLwgItu8r7YCZBA99lYlGUlxtG0b/tBjE75iY4RJeWnsqmul25ohnHF5BPxFYFO/63cDS1R1MrDEu26CoLmjm+c2VHHVrHHQ2+06jgmSKQXpdPcqu+taXUeJWk4KsIgUA1cCv+23+Vrgfu/7+4Hrghwraj27roqObh/Xn2YTtESTouxkUhJi3x16boLP1RHwfwNfA/p/9ilQ1QMA3tdBl+EVkdtFZJWIrKqtteGUo+HR1ZVMyE3ltNIs11FMEMWIMCk/jV31rXT1WDOEC0EvwCJyFVCjqm8dz/1V9T5VnaOqc/LybKXeE7W3oY2Vuxq4/rQim9M3Ck3JT6fXp+yyZggnXBwBnw1cIyK7gYeBC0Xkz0C1iBQCeF9rHGSLOo+trkQE3m/ND1FpXFYSaYlx1hvCkaAXYFX9uqoWq+p44EbgJVX9KLAIuNXb7VbgyWBnizY+n/LoW5WcVT6Goqxk13GMA+I1Q+ypb6Ozp9d1nKgTSv2A7wUuEZFtwCXedRNAy7fXUXmwnZvmlrqOYhyaWpBOryrbauxkXLA5nXFFVV8BXvG+rwcucpkn2jz0RgU5qQksmGHLzkezgoxEslLi2XygmZnjMl3HiSqhdARsgqimqYMXN1XzwdOLSYyzocfRTESYVpjBvsZ2DrVbP/BgsgIcpf72ViU9PuXGM0pcRzEh4KSx/gn4Nx8YbAUyEyhWgKOQz6c8/GYFZ5WPodxmPjNARlI8xdnJbKqy3hDBZAU4Cr26vY69De3cNM9Ovpn3TC/M4FB7N4lF011HiRpWgKPQn17bQ05qApfayTfTz8S8NOJjhdSZF7qOEjWsAEeZvQ1tLNlczU1zS+zkmzlMQlwMk/LSSJ12Lm1dPa7jRAUrwFHmgdf3ECPCR8+0hRfNkWYUZRKTmMpTa/e7jhIVrABHkbauHh5eWcFlM8ZSmGkj38yRxmUm0VW7hwffqHAdJSpYAY4iT6zZT1NHD7e+b7zrKCZEiQgtbz/LO5WHWFd5yHWciGcFOEqoKvev2M20wgzOGG+LjZihtax/ieT4WP6yco/rKBHPCnCUeG1HPVuqm7ntfWU27aQ5Ku1q4+pZhTz59n6aOmxkXCBZAY4Sv162k9y0BK49tch1FBMGbp5XRltXL0+s2ec6SkSzAhwFtlQ1s3RrLbeeNZ4kW3LeDMMpxZmcXJTJH1fsxudT13EilhXgCFVS6m9qEBHO/uS38HV18KWrTn9321AXY8B/Mu5T505gZ20rL222tRECxel0lCZwKvdWsHDxFlo6evjDil2cXJTJnYtWHfN+dy2YGoR0JhxccXIhP3puC/ct28nF023UZCDYEXCEe7uyEVWYXWo9H8zIxMfG8IlzJrBydwNrKg66jhORrABHsM6eXtbtO8Sk/DQyk+NdxzFh6IYzSkhPiuM3y3e6jhKRrABHsLV7D9HV42OO9fs1xyktMY6b55Xx3Poq9tTbysmjzQpwhJKEZNZUHGRCbir56Umu45gw9vGzxxMXG8MvXt7uOkrEsQIcodJPvYKOHh9zx+e4jmLCXEFGEjfPK+Wx1fvYWWsLd44mK8ARqL2rl4y511Gak8LYTDv6NSfuX8+fREJsDD99cZvrKBHFCnAEemhlBbGp2cydYEe/ZnTkpSfy8bPH89Ta/WyydeNGjRXgCNPR3cuvl+2gY887FGXZlJNm9Hxm/kTSk+JY+MJW11EihhXgCPO3tyqpburk0IqHXUcxESYzJZ7PzC/nhY3VvLGz3nWciGAFOIJ09fj4v1d2cFppFh0V77iOYyLQJ88ppygrme8s2kBPr891nLBnBTiC/PXNCvY1tvOli6e4jmIiVHJCLN+6ajqbq5r502s2X/CJsgIcIdq7evnZS9uZOyGHcyfnuo5jItilMwqYPyWPn76wlZrmDtdxwpoV4Ajxp9d2U9vcyVcvnWqzmpmAEhG+e/V0Onp6ueeZza7jhDUrwBGgqaObXy3dwflT8zjDBl6YICjPS+Oz503k8TX7eHFjtes4YcsKcAT43fJdNLZ18xWbStIE0R0XTmZaYQZ3//0d6ls6XccJS1aAw1xDaxe/Xb6Ty2eOZWZRpus4JookxMXw0xtm0dTewzefWI+qrZwxUlaAw9z/Ld1Be3cvd11iPR9M8J00NoO7Fkzh2fVVlJ334WOuuDLYpaS0zPWP4YytiBHGDhxq5/4Vu7ludhGTC9JdxzFR6tPnlvPS5hpe77qRf7vz24xJSxzR/aN5FRY7Ag5j/7V4K6pwp/X7NQ7Fxgg/v2k22tXO0+sO0NVjAzSGywpwmNp0oInHVldy6/vKKMlJcR3HRLmCjCRqF/2IxrZuXtxUbe3Bw2QFOEzd8+xmMpLi+fwFk11HMQaAzr3reN/EMWyraeEtW0NuWKwAh6Hl22pZtrWWOy6cRGaKrfVmQsfpZdlMyU/jn9vr2WGTtx+TFeAQV1JadvhZ45hYbvjPh+lprOLTF0wd8syyMcdNYo6rNwP4R8ldMr2AgoxEnltfZUOVj8F6QYS4yr0VLFy85d3rmw40sXhjNZfNGMvU6zcMeb9oPrNsTpD6DnvNDVffay4uNoarTxnHw2/u5am1B7jhjBLSEq3UDMaOgMNIT6+PFTvqyU9PZEpBmus4xgwpNTGOa2aNo7Onl6fW7qfbpq4clBXgMPJWxUFaOns4d3KuNTOYkJeXnshlM8ZS09zJ4g3WM2IwVoDDRHNHN6t2H2RyfhrF2dbtzISH8rw0zp2cy/baFlbssFU0BrKGmTDx6vY6FDhnks31a8LL7JIsDrZ2sWrPQbJTE5hemOE6UsiwI+AwsK+xna3VLZxelk1GsnU7M+FFRDh/aj7F2cks2VTNvoPtriOFDCvAoU5iWLq1lrTEOOaUZbtOY8xxiY0Rrjy5kIzkeP6xbj+NbV2uI4UEK8AhLu3ki6lt7uScSbnEx9qfy4SvpPhYrp01DhQWrd1PR3ev60jO2X90CDvU3k3W/FsYl5lk3c5MRMhKSeDKUwo51N7Ns+ur8EV5zwgrwCHsJ89vISY5nfOm5Fm3MxMxirNTuGBqPhUNbby+M7p7RlgBDlFv723kz2/soXn10+RnJLmOY8yomlmUyYxxGby5+yDJk+a5juOMFeAQ1NPr4xt/X0d+eiKNyx9wHceYgDh/Sh756YnkXnUXu+paXcdxwgpwCPrjit1sPNDE966ZgXZZlx0TmeJiY7jy5ELU18sdD62msyf6TsoFvQCLSImIvCwim0Rkg4h80dueIyIviMg272tU9rna19jOfy3eykUn5XPpjLGu4xgTUBnJ8dQ/8z+s39fET54f+QRA4c7FEXAP8GVVnQacCXxORKYDdwNLVHUysMS7HnW+86R/hrPvXTvDTryZqNC+402aVz/Nb5bvInnCaVG1mGfQhyKr6gHggPd9s4hsAoqAa4Hzvd3uB14B/l+w87n07LoDvLipmm9ccZLN92Cih/q4+64v8PCbe0n52H9y87xSUhKOXZoiYcpVp23AIjIemA28ARR4xbmvSOc7jBZ09S2dfPOJ9cwsyuDjZ09wHceYoIqLjeGymWPp7Pbx8pZa13GCxlkBFpE04DHgS6raNIL73S4iq0RkVW1tZPyhVJVvPrGe5o4eFn74VBvxZqJSbloi88pz2F7TwtbqZtdxgsLJf7qIxOMvvg+q6t+9zdUiUujdXgjUDHZfVb1PVeeo6py8vLzgBA6wRWv38+z6Ku68ZApTCtJdxzHGmdNLsynISOTlLTW0dva4jhNwLnpBCPA7YJOqLux30yLgVu/7W4Eng53NhQOH2vnOog3MLs3i9vnlruMY41RMjHDJtAK6e5WXtwx6DBZRXBwBnw18DLhQRN72LlcA9wKXiMg24BLvekTr6fXxxYfepqvHx8IPn0psjPV6MGZMWiJnTshhR21rxK+s7KIXxKvAUJXmomBmce1nS7axcncDP71hFhNyU13HMSZkzC7NZnN1M69sqaUkO4WEuMg8LxKZP1UYWLG9jp+/vJ0Pnl7M+2cXu45jTEiJjREunJpPS2cPb+yK3Al7rAAHQUlp2WEdyOMy8rjhv5+jq24vC2+ed9TO5sZEq3FZycwcl8GavY3UNne6jhMQtiZcEFTurWDhYv8wy+5eH4++VUljWzc3nHEqOR9+56j3jYTO5sYcr7Mn5bKjtpWXNtfw4TnFEXdQYkfAQaSqvLipmprmTi6dWUBOaoLrSMaEtKT4WM6dnEtVUwfr9w97uEDYsAIcRCt3N7C1uoX3TRxDea6tcGHMcJw0Np3irGT+ub2Otq7I6htsBThI3qls5PWdDUwbm26LaxozAiLCBSfl09Xr47UIW0HDCnAQpEw9m5e31DJ+TAoXTSuIuHYsYwItJzWBWcVZrN/XFFEn5KwAB9jLm2vIvforFGYmccXJhTbYwpjjNG9CDknxMSzdWotGyGKeVoADaPGGKm5/YBVdtXu4ZtY4m2THmBOQFB/L+8pz2dfYzraayBghZxUhQJ5bf4B/fXA108dlUv3wv5EUH+s6kjFhb0ZRBrlpCby6vQ6JS3Qd54RZAQ6AB17fw78+uJpZJVk88Mm5aGd0LjhozGiLEeG8KXk0d/SQMe8DruOcMCvAo8jnU/7zmU1864n1XDA1nz99Yi4ZSfGuYxkTUYqzU5icn0bGvOvZ1xjei9ZaAR4lHd29fP6h1dy3bCe3nFXGfbfMITXRBhoaEwjnTMoFhHue2eQ6ygmxAjwK6ls6+chvXufZ9VV888ppfO+aGdbbwZgAykiOp2nlY/zjnQOs3NXgOs5xswJ8gnbWtvCBX61gw/4mfnXzaXzq3HLr52tMEDS9/hiFmUl876kN9PrCs1uaFeAT8ObuBj7wqxW0dPTw0O1nctnMQteRjIka2tPJ16+Yxob9TTyyaq/rOMclKgvwwOkhh3uJi0949/vUafP54P8uo3bvLt5ZeAunl+XYlJLGBNnVpxRyxvhsfvz8Fg61dbuOM2JReZao//SQI3HXgqksXLyFNRUHWbatjnGZSVx14VSSP7z0mPczxow+EeG718zg6p+/yk9f3Mp3r5nhOtKIROUR8Il4bUc9y7bVMTEvlffPLiLZBlgY49SMcZncPK+MP722m00HwmvKSivAw+RTJWfB51i5u4EZ4zK44uRC4mxosTEh4csLppCZHM93ntwQVvNEWAUZhl6f8tz6KtJnX86csmwuOimfGGvbNSZkZKUk8LXLTmLl7gYWrd3vOs6wWQE+hl6f8uz6A2yraeHgy7/j7Em5dmLNmBD04TklnFKcyX88vYmWzvCYuN0K8FH4fMriDVXsqG3lvCl5NK183HUkY8wQYmOE710zg5rmTn7+0jbXcYbFCvAQVJUXNlWztaaFcyblcmpJlutIxphjmF2azYfnFPO75bvYUtXsOs4xWQEewvLtdWyuauas8jGcbksIGRM27r58GhnJ8dz993fwhfgIOSvAg1i95yBrKhqZVZzJGeOt+BoTTnJSE/jWVdNYU9HIg2/scR3nqKwAD7Clqpnl2+uYlJ/G/Cl5dsLNmDB03alFnDs5lx8+t4WqQx2u4wzJCnA/VYc6eGFTNUVZyVw6vcC6mhkTpkSE/7juZHp8Pr75xLqQ7RtsBdjT0tnDP97ZT2pCLFfaIAtjwl7pmBS+smAqL26q4W9vVbqOMyirMkBPr49/vLOfrl4fV88aR3KCDS82JhJ84uwJzJuQw/ef2sjehjbXcY4Q9QVYVVmyuYbqpk4WTB9Lblr4L/RnjPGLiRF+8qFZAHzlb2tDrldE1BfgNRWNbK5q5swJOUzKT3MdxxgzykpyUvj21dN5Y1cD9y3f6TrOYaK6AO+ub+VVr8fD3Ak5ruMYYwLkQ6cXc+XJhfz4+S0htYRR1Bbgg61dPLu+ijFpCSyYXmDdzYyJYCLCvdefTGlOCp//y2pqmztdRwKitABLYipPvbOfWBGuPmUc8dbjwZiIl54Uzy9vPo1D7d188eE19PT6XEeKvgLc61Pyrvkqh9q7ufLkQjKS411HMsYcD4kZ8bJi08dlsm/RQlbsqOf7/9jovH9w1C1J9KPnNpNcPofzp+ZTlJ3sOo4x5nip77iWFgP4/j0/5E98gPFjUvnEORNGOdjwRdURcEd3L6/trKd59T84uSjTdRxjjCONL/+By2aM5d+f3sjiDVXOckRVAU6Kj+WRz5xFw5LfuI5ijHFK+ekNp3JKcRZ3PLSGV7fVOUkRVQUY/EUYX6/rGMYYx5ITYvnDbWcwITeVT97/Jiu2B78IR10BNsaYPjmpCTz4qXn+tuD73+SfQS7CVoCNMVFtTFoiD356HmU5qdz2h5U8+fa+oD23FWBjTNTLTUvkkc+cxell2Xzx4bf5xcvbg9JFzQqwMcYAmSnx3P+JuVx76jh+/PwWvvDw2zR3dAf0OaOuH7AxxvQN4hhKxpkfYpHvo/z95TepffJeumt2AVBcUsreitFb5sgKsDEm+gxjEMe+g+08uyGBpE/8L3Mn5HB6WTZfveykUY1hBdgYYwZRlJ3MR+aW8sqWWl7bWc+2mmYSxk4a1eewNmBjjBlCSkIcV5xcyFWnFNLe3cuYK+8c1UndrQAbY8wxTMxL42Pzyqh74l5iYkZv6lorwMYYMwyJ8bF01+8d1ce0AmyMMY5YATbGGEdCrgCLyGUiskVEtovI3a7zGGNMoIRUARaRWOAXwOXAdOAmEZnuNpUxxgRGSBVgYC6wXVV3qmoX8DBwreNMxhgTEKFWgIuA/qcZK71txhgTccT1onT9iciHgEtV9VPe9Y8Bc1X1jn773A7c7l2dChzfolDHlgu4mSZ/+Czj6LCMo8MyDq1OVS8buDHUhiJXAiX9rhcD+/vvoKr3AfcFOoiIrFLVOYF+nhNhGUeHZRwdlnHkQq0J4k1gsohMEJEE4EZgkeNMxhgTECF1BKyqPSLyeeB5IBb4vapucBzLGGMCIqQKMICqPgM84zoHQWjmGAWWcXRYxtFhGUcopE7CGWNMNAm1NmBjjIkaVoAHEJHfi0iNiKx3nWUoIlIiIi+LyCYR2SAiX3SdaSARSRKRlSKy1sv4PdeZBiMisSKyRkT+4TrLUERkt4isE5G3RWSV6zyDEZEsEXlURDZ7r8uzXGfqT0Smer+/vkuTiHzJeS5rgjiciMwHWoA/qepM13kGIyKFQKGqrhaRdOAt4DpV3eg42rvEv+BWqqq2iEg88CrwRVV93XG0w4jIXcAcIENVr3KdZzAishuYo6oh28dWRO4Hlqvqb70eTCmq2ug41qC8KQ/2AfNUdfQWeDsOdgQ8gKouAxpc5zgaVT2gqqu975uBTYTYiEH1a/GuxnuXkHq3F5Fi4Ergt66zhDMRyQDmA78DUNWuUC2+nouAHa6LL1gBDnsiMh6YDbzhOMoRvI/3bwM1wAuqGmoZ/xv4GuBznONYFFgsIm95I0FDTTlQC/zBa875rYikug51FDcCD7kOAVaAw5qIpAGPAV9S1SbXeQZS1V5VPRX/iMa5IhIyTToichVQo6pvuc4yDGer6mn4Zwn8nNdMFkrigNOAX6nqbKAVCMmpZL3mkWuAv7nOAlaAw5bXrvoY8KCq/t11nqPxPo6+AhwxFt6hs4FrvPbVh4ELReTPbiMNTlX3e19rgMfxzxoYSiqByn6fcB7FX5BD0eXAalWtdh0ErACHJe8E1++ATaq60HWewYhInohked8nAxcDm52G6kdVv66qxao6Hv9H0pdU9aOOYx1BRFK9E614H+sXACHVQ0dVq4C9IjLV23QREDInhAe4iRBpfoAQHAnnmog8BJwP5IpIJfAdVf2d21RHOBv4GLDOa2MF+IY3ijBUFAL3e2ecY4BHVDVku3qFsALgcf97LnHAX1T1ObeRBnUH8KD3EX8n8HHHeY4gIinAJcBnXGfpY93QjDHGEWuCMMYYR6wAG2OMI1aAjTHGESvAxhjjiBVgY4xxxAqwMcY4YgXYBISItAyx/RYRWe9NUblRRL7ibf+uiOzrN13gFf3u83UR2S4iW0Tk0iEet2/KxiMWXBSR8YNNLyoixSLypIhsE5EdIvI/Xj/Wvtvnisgr3u2rReRpETm53+1fEpFbRvabGdzA35eIPCciRd7zzxlw28ki8sd+12/wfj/WzzrMWAE2QSMilwNfAhao6gz8w1UP9dvlp6p6qnd5xrvPdPwj1WbgH8r8S29wx2AuUNVhzZfrjSb8O/CEqk4GpgBpwH94txcAj+Af4DLZm4vhHmCid3sc8AngL8P9+YfLGzmYo6r7BrtdVdcBxSJS6l3/K/Cp0c5hAs8KsAmmrwNf6Te3QYeq/uYY97kWeFhVO1V1F7Cd0ZkL4UKgQ1X/4GXpBe4EPuGNmPo8cL+qrui7g6q+qqpP9Lv/alXtAfCOVH8qIsu8CcnPEJG/e0fPP+h7DBG5y/sEsP4oE4Kfj3/ujKN5Cv8bkwljVoBNMM3EP3n8UD4vIu+If1WSbG9bEbC33z6VjM7cxzMGZvFmlKsAJnm3rz7K/c8eeH+gS1XnA/8HPAl8Dv/PfJuIjBGR0/EP0Z0HnAl8WkRmD/LYlwPHGm68Cjj3GPuYEGcF2ISKX+H/eH8qcAD4L2+7DLLvaIyflyEeZ9DtIvKGd2T7P96mQvxz4Pa3yPu6DtjgTZzfiX9uhBLgHOBxVW31Jqv/O4MX0bPxryByNDXAuGPsY0KcFWATTBuA0we7QVWrvfmDfcBveK+ZoRJ/8epTDOw/2pOIyLx+J/OuOUqWgSe3Mrzn2uHd/u6Uiqo6D/gWkOltageSBjxmp/fV1+/7vutxDP5mMjB7ObBXVbuOsWuSl8GEMSvAJpjuAX4kImMBRCRRRL7gfV/Yb7/3896Ui4uAG719JwCTgZVHexJVfaPfybxFQ+y2BEjp68Xgndj7L+CPqtoG/AJ/08H7+t0npd/3m/A3VYzEMuA6EUnxppZ8P7B8wD7DaX4A/0nDkJqW0oycTUdpAiXFm86zz0JVXej1LnjR64WgwO+9238kIqd623bjTRmoqhtE5BH888v2AJ/zTpiN1NQBee7EXwB/KSLfwn8w8gzwDe95q0TkBuCHIlKE/yN/HfB97/7PAg+MJIC3iOofee8N5LequmbAbpfhn9qxv6dFpNv7/jVV/RBwAfD0SJ7fhB6bjtJEBHGwcrCIPA58TVW3jdLjJQL/VNUj+jIPst9S4Jx+vTDOx9/DJCRXdjaDsyYIEylqgSWDDcQIoLvxn4wbFV5Xu+HkLwXu7ld8bwB+CRwcrSwmOOwI2BhjHLEjYGOMccQKsDHGOGIF2BhjHLECbIwxjlgBNsYYR/4/b4djZ1HvPbEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution using Seaborn's displot\n",
    "sns.displot(df_noMV['LC50 [-LOG(mol/L)]'], kde=True)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of LC50 [-LOG(mol/L)]')\n",
    "plt.xlabel('LC50 [-LOG(mol/L)]')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea86cd6d",
   "metadata": {},
   "source": [
    "The distribution plot of LC50 [-LOG(mol/L)] shows:\n",
    "    \n",
    "->Normal Distribution: The histogram and KDE line form a bell-shaped curve, indicating a normal distribution.\n",
    "    \n",
    "->Central Tendency: The peak is around 4 on the x-axis, suggesting this is the most common LC50 value.\n",
    "    \n",
    "->Spread: Values range from approximately 1 to 7.\n",
    "    \n",
    "->Density: The highest density is just above 100.\n",
    "    \n",
    "->Symmetry: The distribution is fairly symmetric around the central value.\n",
    "    \n",
    "These observations indicate that the LC50 [-LOG(mol/L)] values follow a distribution that is approximately normal, with most values clustering around the mean of 4, and a relatively symmetrical spread on either side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c90e78",
   "metadata": {},
   "source": [
    "# Splitting of the dataset as per 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f77630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_noMV\n",
    "\n",
    "X = df_new .drop('LC50 [-LOG(mol/L)]',axis =1)\n",
    "y = df_new['LC50 [-LOG(mol/L)]']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8a832",
   "metadata": {},
   "source": [
    "# Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ede1c9a",
   "metadata": {},
   "source": [
    "1.Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b171b88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.0\n",
      "MAE for this lambda = 0.5551202150390567\n",
      "MSE for this lambda = 0.5372741376554376\n",
      "R for this lambda = 0.6377977108564306\n",
      "Adjusted R for this lambda = 0.6242151250135467\n",
      "------------------\n",
      "lambda = 0.05263157894736842\n",
      "MAE for this lambda = 0.5551867371689805\n",
      "MSE for this lambda = 0.5373348082266768\n",
      "R for this lambda = 0.6377568099117427\n",
      "Adjusted R for this lambda = 0.624172690283433\n",
      "------------------\n",
      "lambda = 0.10526315789473684\n",
      "MAE for this lambda = 0.5552531117994938\n",
      "MSE for this lambda = 0.5373955941122807\n",
      "R for this lambda = 0.6377158312281056\n",
      "Adjusted R for this lambda = 0.6241301748991596\n",
      "------------------\n",
      "lambda = 0.15789473684210525\n",
      "MAE for this lambda = 0.5553193393959279\n",
      "MSE for this lambda = 0.537456494305436\n",
      "R for this lambda = 0.6376747754842607\n",
      "Adjusted R for this lambda = 0.6240875795649204\n",
      "------------------\n",
      "lambda = 0.21052631578947367\n",
      "MAE for this lambda = 0.5553854204216432\n",
      "MSE for this lambda = 0.5375175078063342\n",
      "R for this lambda = 0.6376336433542265\n",
      "Adjusted R for this lambda = 0.62404490498001\n",
      "------------------\n",
      "lambda = 0.2631578947368421\n",
      "MAE for this lambda = 0.5554513553380391\n",
      "MSE for this lambda = 0.5375786336221187\n",
      "R for this lambda = 0.6375924355073357\n",
      "Adjusted R for this lambda = 0.6240021518388608\n",
      "------------------\n",
      "lambda = 0.3157894736842105\n",
      "MAE for this lambda = 0.555517144604566\n",
      "MSE for this lambda = 0.5376398707668335\n",
      "R for this lambda = 0.6375511526082683\n",
      "Adjusted R for this lambda = 0.6239593208310784\n",
      "------------------\n",
      "lambda = 0.3684210526315789\n",
      "MAE for this lambda = 0.5555827886787346\n",
      "MSE for this lambda = 0.5377012182613715\n",
      "R for this lambda = 0.6375097953170876\n",
      "Adjusted R for this lambda = 0.6239164126414785\n",
      "------------------\n",
      "lambda = 0.42105263157894735\n",
      "MAE for this lambda = 0.5556482880161259\n",
      "MSE for this lambda = 0.5377626751334237\n",
      "R for this lambda = 0.6374683642892737\n",
      "Adjusted R for this lambda = 0.6238734279501215\n",
      "------------------\n",
      "lambda = 0.47368421052631576\n",
      "MAE for this lambda = 0.555713643070403\n",
      "MSE for this lambda = 0.5378242404174279\n",
      "R for this lambda = 0.6374268601757583\n",
      "Adjusted R for this lambda = 0.6238303674323493\n",
      "------------------\n",
      "lambda = 0.5263157894736842\n",
      "MAE for this lambda = 0.55577885429332\n",
      "MSE for this lambda = 0.5378859131545193\n",
      "R for this lambda = 0.6373852836229585\n",
      "Adjusted R for this lambda = 0.6237872317588194\n",
      "------------------\n",
      "lambda = 0.5789473684210527\n",
      "MAE for this lambda = 0.5558439221347329\n",
      "MSE for this lambda = 0.5379476923924802\n",
      "R for this lambda = 0.6373436352728097\n",
      "Adjusted R for this lambda = 0.6237440215955401\n",
      "------------------\n",
      "lambda = 0.631578947368421\n",
      "MAE for this lambda = 0.5559088470426093\n",
      "MSE for this lambda = 0.5380095771856911\n",
      "R for this lambda = 0.6373019157627994\n",
      "Adjusted R for this lambda = 0.6237007376039043\n",
      "------------------\n",
      "lambda = 0.6842105263157894\n",
      "MAE for this lambda = 0.5559736294630382\n",
      "MSE for this lambda = 0.5380715665950808\n",
      "R for this lambda = 0.6372601257260007\n",
      "Adjusted R for this lambda = 0.6236573804407257\n",
      "------------------\n",
      "lambda = 0.7368421052631579\n",
      "MAE for this lambda = 0.5560382698402412\n",
      "MSE for this lambda = 0.5381336596880794\n",
      "R for this lambda = 0.6372182657911036\n",
      "Adjusted R for this lambda = 0.62361395075827\n",
      "------------------\n",
      "lambda = 0.7894736842105263\n",
      "MAE for this lambda = 0.5561027686165809\n",
      "MSE for this lambda = 0.5381958555385681\n",
      "R for this lambda = 0.6371763365824495\n",
      "Adjusted R for this lambda = 0.6235704492042914\n",
      "------------------\n",
      "lambda = 0.8421052631578947\n",
      "MAE for this lambda = 0.5561671262325719\n",
      "MSE for this lambda = 0.5382581532268332\n",
      "R for this lambda = 0.6371343387200614\n",
      "Adjusted R for this lambda = 0.6235268764220637\n",
      "------------------\n",
      "lambda = 0.894736842105263\n",
      "MAE for this lambda = 0.5562313431268896\n",
      "MSE for this lambda = 0.5383205518395181\n",
      "R for this lambda = 0.6370922728196767\n",
      "Adjusted R for this lambda = 0.6234832330504146\n",
      "------------------\n",
      "lambda = 0.9473684210526315\n",
      "MAE for this lambda = 0.5562954197363801\n",
      "MSE for this lambda = 0.5383830504695759\n",
      "R for this lambda = 0.6370501394927794\n",
      "Adjusted R for this lambda = 0.6234395197237587\n",
      "------------------\n",
      "lambda = 1.0\n",
      "MAE for this lambda = 0.5563593564960716\n",
      "MSE for this lambda = 0.5384456482162231\n",
      "R for this lambda = 0.637007939346631\n",
      "Adjusted R for this lambda = 0.6233957370721297\n",
      "------------------\n",
      "Best value of lambda = 0.0\n",
      "Best value of MAE for the best lambda = 0.5551202150390567\n",
      "Best value of MSE for the best lambda = 0.5372741376554376\n",
      "Best value of R for the best lambda = 0.6377977108564306\n",
      "Best value of Adjusted R for the best lambda = 0.6242151250135467\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the lambda range\n",
    "lamda = np.linspace(0, 1, 20)\n",
    "\n",
    "# Initialize best parameters\n",
    "best_lamda = 0\n",
    "best_mae = float('inf')  # Initialize to a high value\n",
    "best_mse = float('inf')  # Initialize to a high value\n",
    "best_r2 = float('-inf')  # Initialize to a low value\n",
    "best_adjr2 = float('-inf')  # Initialize to a low value\n",
    "\n",
    "# Train and evaluate the Ridge regression model for each lambda\n",
    "for param in lamda:\n",
    "    RRM = Ridge(alpha=param)\n",
    "    RRM.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = RRM.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    adjusted_r2 = 1 - (1-r2) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "    \n",
    "    print(f\"lambda = {param}\")\n",
    "    print(f\"MAE for this lambda = {mae}\")\n",
    "    print(f\"MSE for this lambda = {mse}\")\n",
    "    print(f\"R for this lambda = {r2}\")\n",
    "    print(f\"Adjusted R for this lambda = {adjusted_r2}\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_lamda = param\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_lamda = param\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_lamda = param\n",
    "\n",
    "    if adjusted_r2 > best_adjr2:\n",
    "        best_adjr2 = adjusted_r2\n",
    "        best_lamda = param\n",
    "\n",
    "print(f\"Best value of lambda = {best_lamda}\")\n",
    "print(f\"Best value of MAE for the best lambda = {best_mae}\")\n",
    "print(f\"Best value of MSE for the best lambda = {best_mse}\")\n",
    "print(f\"Best value of R for the best lambda = {best_r2}\")\n",
    "print(f\"Best value of Adjusted R for the best lambda = {best_adjr2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d058ac7",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "# Best Lambda Value: 0.0\n",
    "\n",
    "# ->The optimal value of lambda (regularization parameter) found through the Ridge regression is 0.0. This implies no regularization was applied, allowing the model to fit the data without penalty on coefficients.\n",
    "\n",
    "# Best MAE: 0.5551\n",
    "\n",
    "# ->The MAE for the best lambda is 0.5551. This value indicates the average absolute difference between the predicted and actual values. A lower MAE suggests better predictive accuracy, indicating that, on average, the model's predictions are close to the actual values.\n",
    "\n",
    "# Best MSE: 0.5372\n",
    "\n",
    "# ->Mean Squared Error (MSE): The MSE for the best lambda is 0.5372. MSE measures the average squared difference between predicted values and actual values. A lower MSE indicates better predictive accuracy, suggesting that the model's predictions are generally closer to the actual values.\n",
    "\n",
    "# Best R: 0.6377\n",
    "\n",
    "# ->The R score for the best lambda is 0.6377. R measures the proportion of the variance in the dependent variable that is predictable from the independent variables. An R of 0.6274 indicates that approximately 62.74% of the variability in the target variable is explained by the model. This indicates a strong fit of the model to the data.\n",
    "\n",
    "# Best Adjusted R: 0.6242\n",
    "\n",
    "# ->The adjusted R for the best lambda is 0.6242. Adjusted R adjusts the R value based on the number of predictors in the model, providing a more accurate measure of model performance. It accounts for the complexity added by additional predictors, showing a slightly more conservative estimate of the model's explanatory power.\n",
    "\n",
    "# Final Verdict:\n",
    "\n",
    "# ->Model Selection: The Ridge regression with a lambda of 0.0 was selected as the best model, indicating that no regularization was necessary to achieve optimal performance.\n",
    "\n",
    "# ->Predictive Accuracy: The low MAE and MSE suggests that the model's predictions are generally close to the actual values, demonstrating good predictive accuracy.\n",
    "\n",
    "# ->Explanatory Power: The high R and adjusted R values indicate that the model explains a significant proportion of the variance in the target variable, reflecting its strong fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dc4d4",
   "metadata": {},
   "source": [
    "# 2. Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9724e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CIC0</th>\n",
       "      <td>0.303356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <td>1.130540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATS1i</th>\n",
       "      <td>-0.550089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NdsCH</th>\n",
       "      <td>0.439784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NdssC</th>\n",
       "      <td>-0.003038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLOGP</th>\n",
       "      <td>0.427427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficients\n",
       "CIC0           0.303356\n",
       "SM1_Dz(Z)      1.130540\n",
       "GATS1i        -0.550089\n",
       "NdsCH          0.439784\n",
       "NdssC         -0.003038\n",
       "MLOGP          0.427427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept is 2.147564926802641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model fitting\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "#predict the outcomes\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "coefficients = pd.DataFrame(lm.coef_,X.columns)\n",
    "coefficients.columns = ['coefficients']\n",
    "display(coefficients)\n",
    "\n",
    "print(\"intercept is {}\".format(lm.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93fb8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 0.6377977108564303\n",
      "Adjusted R: 0.6242151250135465\n",
      "Mean Absolute Error (MAE): 0.5551202150390567\n",
      "Mean Squared Error (MSE): 0.5372741376554379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "# Calculate R\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate Adjusted R\n",
    "adjusted_r2 = 1 - (1-r2) * (len(y_test)-1) / (len(y_test)-X_test.shape[1]-1)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the model performance metrics\n",
    "print(f\"R: {r2}\")\n",
    "print(f\"Adjusted R: {adjusted_r2}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf4db0",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "# R (Coefficient of Determination): 0.6377\n",
    "\n",
    "# ->This indicates that approximately 62.74% of the variance in the dependent variable is explained by the independent variables in the model. This is a substantial proportion, showing a strong fit to the data.\n",
    "\n",
    "# Adjusted R: 0.6242\n",
    "\n",
    "# ->This value is adjusted for the number of predictors in the model and is slightly lower than R, indicating that not all independent variables significantly contribute to the model. It provides a more conservative estimate of the model's explanatory power, accounting for the complexity of the model.\n",
    "\n",
    "# Mean Absolute Error (MAE): 0.5551\n",
    "\n",
    "# ->On average, the model's predictions are 0.5581 units away from the actual values, showing the average magnitude of errors in the predictions. A lower MAE indicates better predictive accuracy, suggesting that the model's predictions are generally close to the actual values.\n",
    "\n",
    "# Mean Squared Error (MSE): 0.5372\n",
    "\n",
    "# ->The Mean Squared Error (MSE) for the model is 0.5532. MSE quantifies the average squared difference between predicted values and actual values. A lower MSE indicates that, on average, the model's predictions are closer to the actual values, demonstrating effective predictive accuracy in minimizing errors.\n",
    "\n",
    "# These metrics suggest that the model explains a substantial proportion of the variance (R and Adjusted R) and has a relatively low average error (MAE) and squared error (MSE), indicating strong predictive accuracy. While the fit is good, there may still be room for improvement in prediction accuracy and further reduction in errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52b7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Assuming your data is in X (features) and y (target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ea7bf",
   "metadata": {},
   "source": [
    "# Define the Models and Hyperparameter Space# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f755fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'LinearRegression': {\n",
    "        'fit_intercept': [True, False]\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'kernel': ['linear', 'poly', 'rbf'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35f9c2",
   "metadata": {},
   "source": [
    "# Implement Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c0cbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing LinearRegression...\n",
      "Best parameters for LinearRegression: {'fit_intercept': True}\n",
      "Best cross-validation MSE for LinearRegression: 0.7394777628224084\n",
      "Optimizing RandomForestRegressor...\n",
      "Best parameters for RandomForestRegressor: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best cross-validation MSE for RandomForestRegressor: 0.6194515869858741\n",
      "Optimizing SVR...\n",
      "Best parameters for SVR: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best cross-validation MSE for SVR: 0.628740609613565\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Optimizing {model_name}...\")\n",
    "    grid_search = GridSearchCV(estimator=models[model_name], param_grid=param_grid[model_name], \n",
    "                               cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation MSE for {model_name}: {-grid_search.best_score_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207af856",
   "metadata": {},
   "source": [
    "# Evaluate the Best Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd94d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression Performance on Test Data:\n",
      "Mean Squared Error (MSE): 0.5506042833659728\n",
      "Mean Absolute Error (MAE): 0.5669903836500387\n",
      "R-squared (R): 0.5993568592559462\n",
      "Root Mean Squared Error (RMSE): 0.7420271446288018\n",
      "\n",
      "RandomForestRegressor Performance on Test Data:\n",
      "Mean Squared Error (MSE): 0.4928768160016702\n",
      "Mean Absolute Error (MAE): 0.5215462459215734\n",
      "R-squared (R): 0.6413618245835794\n",
      "Root Mean Squared Error (RMSE): 0.7020518613333848\n",
      "\n",
      "SVR Performance on Test Data:\n",
      "Mean Squared Error (MSE): 0.42167506605564525\n",
      "Mean Absolute Error (MAE): 0.49465634531246183\n",
      "R-squared (R): 0.6931712521282747\n",
      "Root Mean Squared Error (RMSE): 0.6493651253768139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_performance = {}\n",
    "for model_name, model in best_models.items():\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    model_performance[model_name] = {\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'R': r2,\n",
    "        'RMSE': rmse\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name} Performance on Test Data:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R): {r2}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09067e64",
   "metadata": {},
   "source": [
    "# Compare Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8be238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            MSE       MAE        R      RMSE\n",
      "LinearRegression       0.550604  0.566990  0.599357  0.742027\n",
      "RandomForestRegressor  0.492877  0.521546  0.641362  0.702052\n",
      "SVR                    0.421675  0.494656  0.693171  0.649365\n",
      "Best model based on MSE: SVR\n",
      "Best model based on MAE: SVR\n",
      "Best model based on R: SVR\n",
      "Best model based on RMSE: SVR\n"
     ]
    }
   ],
   "source": [
    "performance_df = pd.DataFrame(model_performance).T\n",
    "print(performance_df)\n",
    "\n",
    "# Identify the best model based on different metrics\n",
    "best_model_mse = performance_df['MSE'].idxmin()\n",
    "best_model_mae = performance_df['MAE'].idxmin()\n",
    "best_model_r2 = performance_df['R'].idxmax()\n",
    "best_model_rmse = performance_df['RMSE'].idxmin()\n",
    "\n",
    "print(f\"Best model based on MSE: {best_model_mse}\")\n",
    "print(f\"Best model based on MAE: {best_model_mae}\")\n",
    "print(f\"Best model based on R: {best_model_r2}\")\n",
    "print(f\"Best model based on RMSE: {best_model_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21c32e",
   "metadata": {},
   "source": [
    "# INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20947b7",
   "metadata": {},
   "source": [
    "Best Overall Model:\n",
    "\n",
    "If one model consistently outperforms others across most or all metrics, it can be considered the best overall model. For example, if RandomForestRegressor has the lowest MSE, MAE, and RMSE and the highest R, it is likely the best model.\n",
    "Trade-offs Between Models:\n",
    "\n",
    "Sometimes, a model may have the lowest MAE but not the lowest MSE. This suggests that while it performs well on average, it might have some large errors affecting its MSE. Choosing between such models depends on the specific requirements of the application.\n",
    "Model Robustness:\n",
    "\n",
    "High variance in the R values across different models indicates how much of the variability each model explains. A model with a significantly higher R is likely more robust.\n",
    "Complexity vs. Performance:\n",
    "\n",
    "More complex models like RandomForestRegressor or SVR might perform better than simpler models like LinearRegression but at the cost of increased computational resources and longer training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7660d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
